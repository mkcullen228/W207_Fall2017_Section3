{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and test a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use the iris data. \n",
    "\n",
    "Goals for this notebook:\n",
    "1. Understand NB well enough to make a prediction by hand\n",
    "2. Use the naive_bayes module in scikit-learn\n",
    "3. First glimpse at the pandas package for manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zalexander/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris feature values are real valued measurements in centimeters. Let's look at histograms of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAADSCAYAAAA7WjOOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\napIkSZLUMSZqkiRJktQx/xdBaT0+JHwffAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11888e4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new figure and set the figsize argument so we get square-ish plots of the 4 features.\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "# Iterate over the features, creating a subplot with a histogram for each one.\n",
    "for feature in range(X_train.shape[1]):\n",
    "    plt.subplot(1, 4, feature+1)\n",
    "    plt.hist(X_train[:,feature], 20)\n",
    "    plt.title(iris.feature_names[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things simple, let's binarize these feature values. That is, we'll treat each measurement as either \"short\" or \"long\". I'm just going to choose a threshold for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.9  3.   4.2  1.5]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 6.7  3.3  5.7  2.5]]\n",
      "[[ 0.  0.  1.  1.]\n",
      " [ 0.  0.  1.  1.]\n",
      " [ 1.  0.  1.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Define a function that applies a threshold to turn real valued iris features into 0/1 features.\n",
    "# 0 will mean \"short\" and 1 will mean \"long\".\n",
    "def binarize_iris(data, thresholds=[6.0, 3.0, 2.5, 1.0]):\n",
    "    # Initialize a new feature array with the same shape as the original data.\n",
    "    binarized_data = np.zeros(data.shape)\n",
    "\n",
    "    # Apply a threshold  to each feature.\n",
    "    for feature in range(data.shape[1]):\n",
    "        binarized_data[:,feature] = data[:,feature] > thresholds[feature]\n",
    "    return binarized_data\n",
    "\n",
    "# Create new binarized training and test data\n",
    "binarized_train_data = binarize_iris(X_train)\n",
    "binarized_test_data = binarize_iris(X_test)\n",
    "\n",
    "print X_train[:10, ]\n",
    "print binarized_train_data[:10, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that Naive Bayes assumes conditional independence of features. With $Y$ the set of labels and $X$ the set of features ($y$ is a specific label and $x$ is a specific feature), Naive Bayes gives the probability of a label $y$ given input features $X$ as:\n",
    "\n",
    "$ \\displaystyle P(y|X) \\approx \n",
    "  \\frac { P(y) \\prod_{x \\in X} P(x|y) }\n",
    "        { \\sum_{y \\in Y} P(y) \\prod_{x \\in X} P(x|y) }\n",
    "$\n",
    "\n",
    "Let's estimate some of these probabilities using maximum likelihood, which is just a matter of counting and normalizing. We'll start with the prior probability of the label $P(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         setosa : 0.33\n",
      "     versicolor : 0.30\n",
      "      virginica : 0.37\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for all labels to zero.\n",
    "label_counts = [0 for i in iris.target_names]\n",
    "\n",
    "# Iterate over labels in the training data and update counts.\n",
    "for label in y_train:\n",
    "    label_counts[label] += 1\n",
    "\n",
    "# Normalize counts to get a probability distribution.\n",
    "total = sum(label_counts)\n",
    "label_probs = [1.0 * count / total for count in label_counts]\n",
    "for (prob, name) in zip(label_probs, iris.target_names):\n",
    "    print '%15s : %.2f' %(name, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat above three cells using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows us to stop thinking about code in terms of procedures, and start thinking about code in terms of _data manipulation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check out pandas here: pandas.pydata.org\n",
    "- [Here](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) is cheat sheet to get a sense for what is possible.\n",
    "- [This](http://pandas.pydata.org/pandas-docs/stable/10min.html) is probably the best place to get started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data into a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df = pd.DataFrame(X, columns=colnames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.Series(y)\n",
    "df['target'] = target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace({'target': {0: 'setosa', 1: 'versicolor', 2: 'virginica'}})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bf96250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = train_df.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length sepal_width petal_length petal_width\n",
       "61         False       False         True        True\n",
       "92         False       False         True        True\n",
       "112         True       False         True        True\n",
       "2          False        True        False       False\n",
       "141         True        True         True        True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.array([6, 3, 2.5, 1])\n",
    "train_df_binarized = train_df[colnames].apply(lambda row: row > thresholds, axis=1)\n",
    "test_df_binarized = test_df[colnames].apply(lambda row: row > thresholds, axis=1)\n",
    "train_df_binarized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     0.366071\n",
       "setosa        0.330357\n",
       "versicolor    0.303571\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes by Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's estimate $P(X|Y)$, that is, the probability of each feature given each label. Remember that we can get the conditional probability from the joint distribution:\n",
    "\n",
    "$\\displaystyle P(X|Y) = \\frac{ P(X,Y) } { P(Y) } \\approx \\frac{ \\textrm{Count}(X,Y) } { \\textrm{Count}(Y) }$\n",
    "\n",
    "Let's think carefully about the size of the count matrix we need to collect. There are 3 labels $y_1$, $y_2$, and $y_3$ and 4 features $x_0$, $x_1$, $x_2$, and $x_3$. Each feature has 2 possible values, 0 or 1. So there are actually $4 \\times 2 \\times 3=24$ probabilities we need to estimate: \n",
    "\n",
    "$P(x_0=0, Y=y_0)$\n",
    "\n",
    "$P(x_0=1, Y=y_0)$\n",
    "\n",
    "$P(x_1=0, Y=y_0)$\n",
    "\n",
    "$P(x_1=1, Y=y_0)$\n",
    "\n",
    "...\n",
    "\n",
    "However, we already estimated (above) the probability of each label. And, we know that each feature value is either 0 or 1. So, for example,\n",
    "\n",
    "$P(x_0=0, Y=\\textrm{setosa}) + P(x_0=1, Y=\\textrm{setosa}) = P(Y=\\textrm{setosa}) \\approx 0.31$.\n",
    "\n",
    "As a result, we can just estimate probabilities for one of the feature values, say, $x_i = 1$. This requires a $4 \\times 3$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length sepal_width petal_length petal_width      target\n",
       "61         False       False         True        True  versicolor\n",
       "92         False       False         True        True  versicolor\n",
       "112         True       False         True        True   virginica\n",
       "2          False        True        False       False      setosa\n",
       "141         True        True         True        True   virginica"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_binarized['target'] = train_df['target']\n",
    "train_df_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal_length  sepal_width  petal_length  petal_width\n",
       "target                                                          \n",
       "setosa          0.000000     0.837838           0.0     0.000000\n",
       "versicolor      0.352941     0.176471           1.0     0.852941\n",
       "virginica       0.829268     0.365854           1.0     1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probs = train_df_binarized.groupby('target').mean()\n",
    "conditional_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is P(sepal length > 1 | versicolor) = .35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     0.366071\n",
       "setosa        0.330357\n",
       "versicolor    0.303571\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = train_df_binarized['target'].value_counts(normalize=True)\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the pieces, let's try making a prediction for the first test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length          5.8\n",
       "sepal_width           2.8\n",
       "petal_length          5.1\n",
       "petal_width           2.4\n",
       "target          virginica\n",
       "Name: 114, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instance = test_df.iloc[0]\n",
    "test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    False\n",
       "sepal_width     False\n",
       "petal_length     True\n",
       "petal_width      True\n",
       "Name: 114, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instance_binarized = test_df_binarized.iloc[0]\n",
    "test_instance_binarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Let's step through the process of computing what Naive Bayes has to say about this specific test example. That is, we want to compute:\n",
    "- P('versicolor' | test_example_binarized)\n",
    "- P('virginica' | test_example_binarized)\n",
    "- P('setosa' | test_example_binarized)\n",
    "\n",
    "All the information we need is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginica     0.366071\n",
      "setosa        0.330357\n",
      "versicolor    0.303571\n",
      "Name: target, dtype: float64\n",
      "\n",
      "            sepal_length  sepal_width  petal_length  petal_width\n",
      "target                                                          \n",
      "setosa          0.000000     0.837838           0.0     0.000000\n",
      "versicolor      0.352941     0.176471           1.0     0.852941\n",
      "virginica       0.829268     0.365854           1.0     1.000000\n",
      "\n",
      "sepal_length    False\n",
      "sepal_width     False\n",
      "petal_length     True\n",
      "petal_width      True\n",
      "Name: 114, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print priors\n",
    "print\n",
    "print conditional_probs\n",
    "print\n",
    "print test_instance_binarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Write a function that takes a label as input and returns _log of the numerator_ of the NB equation. That is, $\n",
    "\\log \\left[ P(y) * P(x | y) \\right]\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognum(label):\n",
    "    \"\"\"\n",
    "    For this function, we imagine a hard coded observation:\n",
    "        \n",
    "        test_example = [sepal_length=False, sepal_width=False, petal_length=True, petal_width=True]\n",
    "        \n",
    "    Input: (string) One of 'versicolor', 'viriginica', or 'setosa'\n",
    "    Output: log P(test_example | label) (using the independence assumption)\n",
    "    \"\"\"    \n",
    "    p_label = priors[label]\n",
    "    p_sl = 1 - conditional_probs.loc[label, 'sepal_length']\n",
    "    p_sw = 1 - conditional_probs.loc[label, 'sepal_width']\n",
    "    p_pl = conditional_probs.loc[label, 'petal_length']\n",
    "    p_pw = conditional_probs.loc[label, 'petal_width']\n",
    "    return np.sum(np.log([p_label, p_sl, p_sw, p_pl, p_pw]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.228064250922607"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'virginica'\n",
    "lognum('virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Compute the log of the numberator for each possible label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zalexander/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "setosa            -inf\n",
       "versicolor   -1.980677\n",
       "virginica    -3.228064\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lognums = pd.Series({label: lognum(label) for label in ('virginica', 'setosa', 'versicolor')})\n",
    "lognums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posterior = P(y | X) = prior * likelihood / evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: Convert the results of (2) into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        0.000000\n",
       "versicolor    0.776847\n",
       "virginica     0.223153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lognums.apply(np.exp) / lognums.apply(np.exp).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB means _the features are distributed Bernoulli_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63157894736842102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB(alpha=100)\n",
    "nb.fit(train_df_binarized[colnames], train_df.target)\n",
    "\n",
    "predicted_probabilities = nb.predict_proba(test_df_binarized[colnames])\n",
    "pred = nb.predict(test_df_binarized[colnames])\n",
    "\n",
    "correct = pred == test_df['target']\n",
    "accuracy = np.mean(correct)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326999</td>\n",
       "      <td>0.349198</td>\n",
       "      <td>0.323803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.202491</td>\n",
       "      <td>0.306733</td>\n",
       "      <td>0.490776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202491</td>\n",
       "      <td>0.306733</td>\n",
       "      <td>0.490776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.202491</td>\n",
       "      <td>0.306733</td>\n",
       "      <td>0.490776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.477482</td>\n",
       "      <td>0.277751</td>\n",
       "      <td>0.244766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.477482</td>\n",
       "      <td>0.277751</td>\n",
       "      <td>0.244766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.326999</td>\n",
       "      <td>0.349198</td>\n",
       "      <td>0.323803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.202491</td>\n",
       "      <td>0.306733</td>\n",
       "      <td>0.490776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.501622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.565493</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.406099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      setosa  versicolor  virginica\n",
       "0   0.212304    0.381596   0.406099\n",
       "1   0.326999    0.349198   0.323803\n",
       "2   0.565493    0.220423   0.214084\n",
       "3   0.152849    0.345530   0.501622\n",
       "4   0.565493    0.220423   0.214084\n",
       "5   0.202491    0.306733   0.490776\n",
       "6   0.565493    0.220423   0.214084\n",
       "7   0.202491    0.306733   0.490776\n",
       "8   0.152849    0.345530   0.501622\n",
       "9   0.152849    0.345530   0.501622\n",
       "10  0.152849    0.345530   0.501622\n",
       "11  0.202491    0.306733   0.490776\n",
       "12  0.152849    0.345530   0.501622\n",
       "13  0.152849    0.345530   0.501622\n",
       "14  0.152849    0.345530   0.501622\n",
       "15  0.565493    0.220423   0.214084\n",
       "16  0.212304    0.381596   0.406099\n",
       "17  0.212304    0.381596   0.406099\n",
       "18  0.477482    0.277751   0.244766\n",
       "19  0.565493    0.220423   0.214084\n",
       "20  0.212304    0.381596   0.406099\n",
       "21  0.212304    0.381596   0.406099\n",
       "22  0.565493    0.220423   0.214084\n",
       "23  0.477482    0.277751   0.244766\n",
       "24  0.152849    0.345530   0.501622\n",
       "25  0.565493    0.220423   0.214084\n",
       "26  0.565493    0.220423   0.214084\n",
       "27  0.152849    0.345530   0.501622\n",
       "28  0.326999    0.349198   0.323803\n",
       "29  0.565493    0.220423   0.214084\n",
       "30  0.202491    0.306733   0.490776\n",
       "31  0.212304    0.381596   0.406099\n",
       "32  0.565493    0.220423   0.214084\n",
       "33  0.152849    0.345530   0.501622\n",
       "34  0.152849    0.345530   0.501622\n",
       "35  0.212304    0.381596   0.406099\n",
       "36  0.565493    0.220423   0.214084\n",
       "37  0.212304    0.381596   0.406099"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predicted_probabilities, columns=['setosa', 'versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB _means the features are distributed Gaussian_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Build a GaussianNB model using sklearn, and estimate the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_df[colnames], train_df['target'])\n",
    "nb.score(test_df[colnames], test_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at those predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.786004e-230</td>\n",
       "      <td>1.238168e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.925996e-84</td>\n",
       "      <td>9.999984e-01</td>\n",
       "      <td>1.586474e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.496146e-18</td>\n",
       "      <td>1.747601e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.156663e-310</td>\n",
       "      <td>5.337438e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.421680e-17</td>\n",
       "      <td>1.232001e-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          setosa    versicolor     virginica\n",
       "0  3.786004e-230  1.238168e-06  9.999988e-01\n",
       "1   3.925996e-84  9.999984e-01  1.586474e-06\n",
       "2   1.000000e+00  1.496146e-18  1.747601e-27\n",
       "3  3.156663e-310  5.337438e-07  9.999995e-01\n",
       "4   1.000000e+00  9.421680e-17  1.232001e-26"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities = pd.DataFrame(nb.predict_proba(test_df[colnames]), \n",
    "                                       columns=['setosa', 'versicolor', 'virginica'])\n",
    "predicted_probabilities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probabilities are _very_ confident. Since the test predictions are also extremely accurate, we might conclude that GaussianNB is an appropriate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB _means the features are distributed multinomial_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "0.0          0.00          0.0          0.00         0.00\n",
      "0.2          5.02          2.7          1.50         0.20\n",
      "0.4          5.60          3.0          3.90         1.14\n",
      "0.6          6.16          3.1          4.70         1.50\n",
      "0.8          6.70          3.4          5.48         2.00\n",
      "1.0         10.00         10.0         10.00        10.00\n"
     ]
    }
   ],
   "source": [
    "cuts = [0, .2, .4, .6, .8, 1]\n",
    "breaks = train_df[colnames].quantile(cuts)\n",
    "breaks.loc[0, :] = 0  # Set a global minimimum\n",
    "breaks.loc[1, :] = 10  # Set a global maximum\n",
    "print breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize each column according to the breaks defined above\n",
    "train_df_mult = train_df[colnames].apply(\n",
    "    lambda col: pd.cut(col, bins=breaks[col.name], include_lowest=True, labels=False)\n",
    ")\n",
    "test_df_mult = test_df[colnames].apply(\n",
    "    lambda col: pd.cut(col, bins=breaks[col.name], include_lowest=True, labels=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "61              2            1             2            2\n",
       "92              2            0             2            2\n",
       "112             4            1             4            4\n",
       "2               0            3             0            0\n",
       "141             4            2             3            4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57894736842105265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(alpha=1)\n",
    "nb.fit(train_df_mult, train_df['target'])\n",
    "nb.score(test_df_mult, test_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "\n",
    "Consider the following threshold possibilities for each of the four features.\n",
    "\n",
    "```\n",
    "sepal_length_thresh = [5.0, 5.6, 6.2, 6.5]\n",
    "sepal_width_thresh = [2.7, 3.0, 3.2, 3.4]\n",
    "petal_length_thresh = [2, 3, 4, 5]\n",
    "petal_width_thresh = [.5, 1, 1.5, 2]\n",
    "```\n",
    "\n",
    "Find the combination of thresholds (one from each list), that gives the BernoulliNB model with the highest accuracy.\n",
    "\n",
    "Use a train/test/dev split, and report accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
