{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and test a Nearest Neighbors classifier.\n",
    "\n",
    "- We will try to build the best possible nearest neighbors classifier for a specific data set. By 'best', we mean _highest accuracy_\n",
    "- Use a train/dev/test split\n",
    "- Experiment with as many hyper-parameters as possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris data to use for experiments. The data include 50 observations of each of 3 types of irises (150 total). Each observation includes 4 measurements: sepal and petal width and height. The goal is to predict the iris type from these measurements.\n",
    "\n",
    "<http://en.wikipedia.org/wiki/Iris_flower_data_set>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is fairly well behaved. For now, we are going to skip EDA and feature engineering---which would normally be essential steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break off a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "test_size = 50\n",
    "test_idx = np.random.choice(X.shape[0], test_size, replace=False)\n",
    "train_idx = np.setdiff1d(range(X.shape[0]), test_idx)\n",
    "\n",
    "X_train, y_train = X[train_idx, :], y[train_idx]\n",
    "X_test, y_test = X[test_idx, :], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   3,   4,   5,   6,   9,  11,  12,  13,  14,  15,  17,\n",
       "        19,  20,  21,  23,  25,  28,  29,  30,  31,  32,  34,  35,  36,\n",
       "        38,  39,  41,  42,  46,  47,  48,  49,  50,  52,  53,  55,  56,\n",
       "        57,  58,  64,  65,  67,  68,  69,  70,  72,  74,  75,  77,  79,\n",
       "        80,  81,  82,  85,  87,  88,  89,  91,  94,  95,  96,  98,  99,\n",
       "       101, 102, 103, 104, 105, 106, 109, 110, 111, 113, 115, 117, 118,\n",
       "       120, 122, 123, 124, 125, 128, 129, 130, 131, 133, 135, 136, 138,\n",
       "       139, 140, 142, 143, 145, 146, 147, 148, 149])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114,  62,  33, 107,   7, 100,  40,  86,  76,  71, 134,  51,  73,\n",
       "        54,  63,  37,  78,  90,  45,  16, 121,  66,  24,   8, 126,  22,\n",
       "        44,  97,  93,  26, 137,  84,  27, 127, 132,  59,  18,  83,  61,\n",
       "        92, 112,   2, 141,  43,  10,  60, 116, 144, 119, 108])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we set aside the test set. We should only touch the test set once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training set into development train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "dev_size = 30\n",
    "devtest_idx = np.random.choice(train_idx, dev_size, replace=False)\n",
    "devtrain_idx = np.setdiff1d(train_idx, devtest_idx)\n",
    "\n",
    "# Split into train and dev.\n",
    "X_devtrain, y_devtrain = X[devtrain_idx, :], y[devtrain_idx]\n",
    "X_devtest, y_devtest = X[devtest_idx, :], y[devtest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(50, 4)\n",
      "(100, 4)\n",
      "(70, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print X_test.shape\n",
    "print X_train.shape\n",
    "print X_devtrain.shape\n",
    "print X_devtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a distance function that returns the distance between 2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(v1, v2):\n",
    "    return np.sum((v1 - v2) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's compute all the pairwise distances in the training data and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL0mNM+glqXH/BzRnYyR2zAzUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ca8610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dists = []\n",
    "for i in range(len(X_train) - 1):\n",
    "    for j in range(i + 1, len(X_train)):\n",
    "        dist = EuclideanDistance(X_train[i], X_train[j])\n",
    "        dists.append(dist)\n",
    "        \n",
    "fig = plt.hist(dists, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pythonic (scienthonic?) versions of the above two cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is great for data science because there are a ton of high-level, commonly used, and often vectorized operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL0mNM+glqXH/BzRnYyR2zAzUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119412ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dists = pdist(X_train, metric=EuclideanDistance)\n",
    "\n",
    "fig = plt.hist(dists, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-NN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now let's create a class that implements a Nearest Neighbors classifier. We'll model it after the sklearn classifier implementations, with fit() and predict() methods.\n",
    "\n",
    "<http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class NearestNeighbors:\n",
    "    \n",
    "    def __init__(self, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, data, labels):\n",
    "        self.train_data = data\n",
    "        self.train_labels = labels\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            results.append(self._predict_item(item))\n",
    "        return results\n",
    "    \n",
    "    def _predict_item(self, item):\n",
    "        \"\"\"\n",
    "        Return the label of the training example closest to item\n",
    "        \"\"\"\n",
    "        distances = cdist([item], self.train_data, self.metric)[0]\n",
    "        best_label = self.train_labels[np.argmin(distances)]\n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "See how well the classifier performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 30  correct: 29  accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "clf = NearestNeighbors()\n",
    "clf.fit(X_devtrain, y_devtrain)\n",
    "preds = clf.predict(X_devtest)\n",
    "\n",
    "correct = np.sum(preds==y_devtest)\n",
    "total = len(y_devtest)\n",
    "print 'total: {}  correct: {}  accuracy: {:.3}'.format(total, correct, 1.0 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k nearest neighbors\n",
    "\n",
    "The implementation above only allows for a single nearest neighbor; that is, the classifier predicts the label of the closest available point. What about using more than one nearest neighbor. Typically, this means to make a prediciton we:\n",
    "\n",
    "1. Find the k closest points (according to our distance metric) to the query point.\n",
    "2. Find the majority label of those k points found in (1)\n",
    "3. Return the label in (2) as the prediction\n",
    "\n",
    "Try implementing this strategy below.\n",
    "Hint: Check out the `most_common` method in `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class OurKNearestNeighbors:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, k, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "        self.k = k\n",
    "    \n",
    "    # No training for Nearest Neighbors. Just store the data.\n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # Make predictions for each test example and return results.\n",
    "    def predict(self, test_data):\n",
    "        results = [self._predict_item(item) for item in test_data]\n",
    "        return results\n",
    "    \n",
    "    # Private function for making a single prediction using KNN.\n",
    "    def _predict_item(self, item):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "`NearestNeighbors` and `OurKNearestNeighbors` should give the same prediction (when k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfk = OurKNearestNeighbors(k=1)\n",
    "clfk.fit(X_devtrain, y_devtrain)\n",
    "preds = clfk.predict(X_devtest)\n",
    "\n",
    "# test\n",
    "clf = NearestNeighbors()\n",
    "clf.fit(X_devtrain, y_devtrain)\n",
    "preds_nn = clf.predict(X_devtest)\n",
    "\n",
    "print \"Percentage of same predictions: \", np.mean(preds == preds_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking k: the number of neighbors to use in classification\n",
    "\n",
    "Implement a way to pick the number of neighbors to use in the classifier. We already have a test set, so simply extend the procedure in the previous code cell to run over different numbers of neighbors. Plot the test set performance versus the number of neighbors. Remember that we are not yet ready to touch the _actual_ test set. Everything in this cell should use `devtrain` and `devtest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This isn't really enough information. Let's try using more train/dev splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Write a function that splits a training dataset randomly, builds a kNN classifier, and reports the acccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Run the above function 500 times for each value of k between 1 and 15 to get the mean test accuracy for that value of k. (That is, the _devtest_ accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 (optional) - If you would like, now would be the time to experiment with different distance metrics. Repeat the above step and see what the results look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Use Occam's razor to select the best model.\n",
    "\n",
    "Once you have chosen the hyper-parameters for the model (k and distance metric), it is time to deploy the model. Now is the time to test our model on the test set, so that we know what to expect after deployment. Use the chosen parameters to train a KNN model on _all of the training data_ and test the performance on the test set (or final holdout set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results\n",
    "\n",
    "We've been a litte haphazard so far, we should have plotted the data and some results to get an idea of how the algorithm is performing. Plot the data with the true labels as colors, and plot it with some fitted labels, for differing values of k, to see how our KNN algorithm is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_bright = ListedColormap(['#FF0000', '#0000FF', '#00FF00'])\n",
    "\n",
    "plt.figure(figsize=(8,8)) \n",
    "p = plt.subplot(2, 2, 1)\n",
    "p.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright)\n",
    "plt.title(\"Iris Test Data: X1 vs X2\")\n",
    "\n",
    "p = plt.subplot(2, 2, 2)\n",
    "p.scatter(X_test[:, 2], X_test[:, 3], c=y_test, cmap=cm_bright)\n",
    "plt.title(\"Iris Test Data: X3 vs X4\")\n",
    "\n",
    "p = plt.subplot(2, 2, 3)\n",
    "p.scatter(X_test[:, 0], X_test[:, 1], c=preds, cmap=cm_bright)\n",
    "plt.title(\"Iris Test Data: X1 vs X2 [pred colors]\")\n",
    "\n",
    "p = plt.subplot(2, 2, 4)\n",
    "p.scatter(X_test[:, 2], X_test[:, 3], c=preds, cmap=cm_bright)\n",
    "plt.title(\"Iris Test Data: X3 vs X4 [pred colors]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Implement variable scaling. \n",
    "\n",
    "That is, scale each feature to its normalized z-score. Make sure not to contaminate the test set..\n",
    "\n",
    "Repeat steps one and two above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Did variable scaling improve anything? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
