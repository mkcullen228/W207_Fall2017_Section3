{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression\n",
    "\n",
    "- Regression is a technique for supervised learning that is based on strong statistical assumptions about the underlying data. Linear and logistic regression are just two different assumptions on the data\n",
    "- Regression can be used when the assumptions are not met, but then it needs to be graded based on _performance on the test data_. P-values, F-scores, etc.. depend on the assumptions being true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y \\in \\mathbb{R}$ be a random variable (the target) and $X = x_1, \\ldots, x_p$ be a set of _independent_ variables (the predictors). Then\n",
    "$$\n",
    "y \\sim \\cal{N}(\\mu, \\sigma)\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\mu = \\mu(X) = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_p x_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Test Data\n",
    "\n",
    "Let's generate some sample data that matches the assumptions exactly.\n",
    "\n",
    "1. Set p = 3\n",
    "2. Choose a formula for $\\mu(X)$\n",
    "$$\n",
    "\\mu(X) = 5 - 9 x_1 + 3 x_2 + 2 x_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a 100x3 data frame of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.random.rand(100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target (response) is a linear function of the features, plus some gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.834211</td>\n",
       "      <td>0.232512</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630437</td>\n",
       "      <td>0.552745</td>\n",
       "      <td>0.385326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301526</td>\n",
       "      <td>0.510103</td>\n",
       "      <td>0.044230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988131</td>\n",
       "      <td>0.808715</td>\n",
       "      <td>0.825096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266662</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.199670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.834211  0.232512  0.097900\n",
       "1  0.630437  0.552745  0.385326\n",
       "2  0.301526  0.510103  0.044230\n",
       "3  0.988131  0.808715  0.825096\n",
       "4  0.266662  0.024382  0.199670"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "def make_target(row, sigma):\n",
    "        x1, x2, x3 = row[0], row[1], row[2]\n",
    "        mu = 5 - 9*x1 + 3*x2 + 2*x3\n",
    "        y = np.random.normal(mu, sigma)\n",
    "        return y\n",
    "    \n",
    "y = X.apply(lambda row: make_target(row, sigma), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.696840\n",
       "1    1.807866\n",
       "2    3.863586\n",
       "3    0.171248\n",
       "4    3.187623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the formula using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse engineer the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression() #instatiate\n",
    "linreg.fit(X, y) #fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9805044890227474"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.97814622,  2.99952442,  1.99547238])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_ # should match (9,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predicted vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x108425290>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngh0AUoZgB4CUIdgBIGUIdgBImf8H9x1pttbtGRwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114797f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = linreg.predict(X)\n",
    "plt.plot(pred, y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99865210601855103"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y \\in \\{0, 1\\}$ be a random variable (the target) and $X = x_1, \\ldots, x_n$ be a set of _independent_ variables (the predictors). Then\n",
    "$$\n",
    "y \\sim \\cal{Ber}(p)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "p = p(X) = f(w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n)\n",
    "$$\n",
    "and $f$ is the _logistic function_\n",
    "$$\n",
    "f(t) = \\frac{1}{1 + e^{-t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to predict a bianry answer (yes or no, 0 or 1)\n",
    "# give y a standard distribution but doesn't make sense to be normally distributed. so choose burnoli \n",
    "# very similar to minear regression but our assumed distributing of underlying data has changed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Sigmoid?\n",
    "\n",
    "We choose the sigmoid function because it is a transformation of the whole real line to the interval (0, 1). That is, it turns real numbers into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x117c84a50>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117cefc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pts = np.linspace(-10, 10, 100)\n",
    "sig = sigmoid(pts)\n",
    "plt.plot(pts, sig, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Test Data\n",
    "\n",
    "Let's generate some sample data that matches the assumptions exactly.\n",
    "\n",
    "1. Set n = 3\n",
    "2. Choose a formula for $p(X)$\n",
    "$$\n",
    "p(X) = f(5 - 9 x_1 + 3 x_2 + 2 x_3)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Generate logistic regression data according to the model above.\n",
    "\n",
    "1. Use the same feature data (X) as before.\n",
    "2. Delete the target column (use `del X['target']`)\n",
    "3. Make a new target column with values in {0, 1} that is distributed Bernoulli, conditioned on the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.random.rand(100,3))\n",
    "\n",
    "sigma = 0.1\n",
    "def make_target(row):\n",
    "    x1, x2, x3 = row[0], row[1], row[2]\n",
    "    p = sigmoid(5 - 9*x1 + 3*x2 + 2*x3)\n",
    "    return np.random.rand() < p\n",
    "\n",
    "\n",
    "y = X.apply(make_target, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recover coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+18, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit logistic model\n",
    "logit = LogisticRegression(C=1e18)\n",
    "logit.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.00077571])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intercepts\n",
    "logit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.82894759,  3.63927214,  1.66338867]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89000000000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R squared \n",
    "logit.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot predicted vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-69ce80feb84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;34m'wTx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'Predicted Probability'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'Actual'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mauracullen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mauracullen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mauracullen/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mauracullen/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mauracullen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5169)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "        'wTx': X.apply(lambda row: np.dot(row, logit.coef_.flatten()), axis=1),\n",
    "        'Predicted Probability': logit.predict_proba(X)[:,1],\n",
    "        'Actual': X['target']\n",
    "    })\n",
    "\n",
    "ax = results.plot(x='wTx', y='Predicted Probability', kind='scatter', \n",
    "                  label = 'Predicted', color='lightblue')\n",
    "results.plot(x='wTx', y='Actual', kind='scatter', ax=ax, label='Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Regularization is a means for preventing _overfitting_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any type of regression, one learns the model parameters by:\n",
    "\n",
    "1. Assume the probabilistic model is correct.\n",
    "2. Compute the _likelihood_ of each data point for a given set of parameters $w_0, \\ldots, w_p$. (just evaluate the PDF at that point and target value)\n",
    "3. Choose the set of parameters that maximizes the total likelihood. (or, equivalently, minimizes the log-likelihood)\n",
    "\n",
    "For linear regression, it turns out that ${\\cal l} (X) \\sim ||w^T x - y||^2$. So maximizing the likelihood is the same as minimizing the mean-squared error.\n",
    "\n",
    "For logistic regression,\n",
    "$$\n",
    "{\\cal l} (x) := -y \\log(f(w^T x)) - (1 - y) \\log(1 - f(w^Tx))\n",
    "$$\n",
    "\n",
    "In either case, regularization just means that instead of directly minimizing ${\\cal L}(X)$, we also add a penalty on the size of coefficients.\n",
    "\n",
    "#### L1 (Lasso) Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + \\lambda \\sum_{i=1}^p |w_i|\n",
    "$$\n",
    "\n",
    "#### L2 (Ridge) Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + \\lambda \\sum_{i=1}^p ||w_i||^2\n",
    "$$\n",
    "\n",
    "#### Elastic Net Regularization\n",
    "\n",
    "Find $w$ that minimizes \n",
    "$$\n",
    "{\\cal l}(X) + (1 - \\alpha) \\cdot \\lambda \\sum_{i=1}^p |w_i|^2 + \\alpha \\cdot \\lambda \\sum_{i=1}^p ||w_i||\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Crime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminal\n",
    "\n",
    "conda update scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load some crime data\n",
    "headers = pd.read_csv('comm_names.txt', squeeze=True)\n",
    "headers = headers.apply(lambda s: s.split()[1])\n",
    "crime = (pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', \n",
    "                    header=None, na_values=['?'], names=headers)\n",
    "         .iloc[:, 5:]\n",
    "         .dropna()\n",
    "         )\n",
    "\n",
    "# Set target and predictors\n",
    "target = 'ViolentCrimesPerPop'\n",
    "predictors = [c for c in crime.columns if not c == target]\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = train_test_split(crime, random_state=2)  \n",
    "\n",
    "# Wide data set so easy to overfit with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 122)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 122)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  \\\n",
       "54           0.23          0.28          0.76          0.08         0.01   \n",
       "41           0.58          0.01          0.83          0.13         0.21   \n",
       "13           0.47          0.74          0.37          0.08         0.05   \n",
       "1            0.45          0.83          0.34          0.04         0.01   \n",
       "19           0.43          0.04          0.89          0.09         0.06   \n",
       "\n",
       "    agePct12t21  agePct12t29  agePct16t24  agePct65up  numbUrban  \\\n",
       "54         0.32         0.37         0.22        0.61       0.09   \n",
       "41         0.44         0.49         0.29        0.25       0.06   \n",
       "13         0.49         0.57         0.40        0.34       0.27   \n",
       "1          0.48         0.53         0.36        0.37       0.30   \n",
       "19         0.45         0.48         0.31        0.46       0.13   \n",
       "\n",
       "           ...           LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "54         ...               0.08     0.16            0.29       0.09   \n",
       "41         ...               0.05     0.16            0.20       0.06   \n",
       "13         ...               0.63     0.07            0.08       0.37   \n",
       "1          ...               0.39     0.12            0.09       0.04   \n",
       "19         ...               0.16     0.12            0.07       0.04   \n",
       "\n",
       "    PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "54           0.01                 0.56                  0.0   \n",
       "41           0.04                 0.22                  0.5   \n",
       "13           0.04                 0.74                  0.5   \n",
       "1            0.01                 0.00                  0.0   \n",
       "19           0.01                 0.81                  1.0   \n",
       "\n",
       "    LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "54                 1.00             0.12                 0.56  \n",
       "41                 0.59             0.48                 0.09  \n",
       "13                 0.84             0.09                 0.25  \n",
       "1                  0.36             0.01                 0.35  \n",
       "19                 0.56             0.09                 0.63  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "1. Fit a linear regression model on train_df. The goal is to predict 'ViolentCrimesPerPop' from the other columns. What is the r-squared on the train data? What about the test data?\n",
    "2. Also fit each of a ridge, lasso, and elastic net regression on the same data. Use the functions RidgeCV, LassoCV, and ElasticNetCV to cross-validate and find the best values of $\\lambda$ and $\\alpha$. Do this using only _the training set_\n",
    "3. Which model performs the best? Answer this question using _the test set_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linReg = LinearRegression()\n",
    "linreg.fit(train_df[predictors], train_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1395646980719445"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82318616940316736"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(train_df[predictors],train_df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50916546685875996"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(test_df[predictors], test_df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2 0.665866858416\n",
      "test R2 0.714273247025\n",
      "wvec: [-0.00227582  0.08230379 -0.06412292 -0.00772165  0.02677898  0.00539564\n",
      " -0.00832168 -0.00186947  0.01439694  0.00257869  0.01556309 -0.01717738\n",
      " -0.02177307 -0.03498826 -0.04495981  0.01074812  0.02925941 -0.01492379\n",
      " -0.01026583 -0.00583042  0.00158234 -0.00677277 -0.00617339  0.01189401\n",
      "  0.03467641  0.01648832 -0.0101469   0.01873815 -0.02907318 -0.00480109\n",
      " -0.01234768  0.03202148 -0.01993723 -0.05015593  0.0158556   0.00351489\n",
      " -0.00784046  0.0453326   0.02228998  0.03975416  0.04524221  0.00349481\n",
      " -0.06517959 -0.0720009  -0.05581412 -0.04688224  0.01883544  0.01143286\n",
      "  0.00203689  0.08200217 -0.0111038  -0.00700924 -0.00657467  0.00702009\n",
      "  0.019801    0.0014376   0.00874782  0.01676644  0.01652717  0.00231704\n",
      " -0.00248397  0.01872848  0.01136615 -0.00982044  0.00242297 -0.01496559\n",
      " -0.00881304  0.01721259  0.04152964 -0.0238116   0.03939913 -0.020133\n",
      " -0.01033917  0.04326436 -0.00789304 -0.0039359   0.0424721  -0.00996011\n",
      " -0.01646728 -0.01931875 -0.01891966 -0.02172566 -0.00104521 -0.0072904\n",
      "  0.00371471  0.01584946 -0.0032806  -0.00645177  0.02801214  0.07267039\n",
      "  0.00613318 -0.02941743  0.00113237  0.00901205  0.00368166 -0.0115491\n",
      " -0.00909973  0.01455182 -0.00683006  0.00955797  0.02947883  0.04947114\n",
      " -0.00895499 -0.05965788 -0.02631945  0.01697315  0.01208143  0.04291687\n",
      "  0.0105011  -0.01546122  0.00670787 -0.03519875  0.00654364  0.00988253\n",
      "  0.01233058  0.03179851  0.00382965 -0.01017475  0.02721957 -0.02614702\n",
      "  0.01454003]\n",
      "lambda 10.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rr = RidgeCV(alphas=np.power(10., np.arange(-5,6)))\n",
    "rr.fit(train_df[predictors], train_df[target])\n",
    "print 'train R2', rr.score(train_df[predictors], train_df[target])\n",
    "print 'test R2', rr.score(test_df[predictors], test_df[target])\n",
    "print 'wvec:', rr.coef_\n",
    "print 'lambda', rr.alpha_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2 0.684981811291\n",
      "test R2 0.71670875777\n",
      "wvec: [ 0.          0.08178776 -0.         -0.          0.09924475  0.\n",
      " -0.00765088 -0.          0.         -0.          0.         -0.         -0.\n",
      " -0.01205732 -0.19295059  0.          0.         -0.          0.          0.\n",
      " -0.         -0.         -0.          0.          0.11284783  0.         -0.\n",
      "  0.         -0.1126499  -0.         -0.          0.04831336 -0.\n",
      " -0.10203154  0.          0.         -0.          0.01060783 -0.          0.\n",
      "  0.          0.         -0.         -0.55131388 -0.         -0.          0.\n",
      "  0.         -0.          0.08050905 -0.          0.         -0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.          0.\n",
      "  0.          0.          0.          0.         -0.          0.          0.\n",
      "  0.12383203 -0.          0.04124994 -0.          0.          0.02364541\n",
      " -0.          0.          0.01907677 -0.         -0.         -0.02212135\n",
      " -0.00156401 -0.         -0.         -0.         -0.          0.\n",
      " -0.00737647 -0.          0.          0.14742886  0.         -0.          0.\n",
      "  0.          0.         -0.         -0.          0.         -0.         -0.\n",
      "  0.          0.09111629 -0.         -0.05784478 -0.          0.          0.\n",
      "  0.07044707  0.         -0.          0.         -0.04086896  0.         -0.\n",
      " -0.          0.0013192  -0.         -0.          0.02710176 -0.05091095\n",
      "  0.        ]\n",
      "lambda 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lar = LassoCV(alphas=np.power(10., np.arange(-5,6)))\n",
    "lar.fit(train_df[predictors], train_df[target])\n",
    "print 'train R2', lar.score(train_df[predictors], train_df[target])\n",
    "print 'test R2', lar.score(test_df[predictors], test_df[target])\n",
    "print 'wvec:', lar.coef_\n",
    "print 'lambda', lar.alpha_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2 0.650724087416\n",
      "test R2 0.718658990765\n",
      "wvec: [-0.          0.09899698 -0.07396257 -0.          0.02859735  0.         -0.\n",
      "  0.          0.          0.          0.         -0.         -0.         -0.\n",
      " -0.04273575  0.          0.01680586 -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.00025827  0.          0.\n",
      "  0.01102043 -0.          0.         -0.          0.03104448 -0.\n",
      " -0.05750859  0.          0.         -0.          0.04502578  0.\n",
      "  0.02583623  0.04411929  0.         -0.09329905 -0.10926846 -0.06306402\n",
      " -0.04312344  0.          0.          0.          0.1091917   0.         -0.\n",
      "  0.          0.          0.          0.          0.          0.00246674\n",
      "  0.00482013 -0.          0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.01391855  0.04955475 -0.0207441   0.04904405\n",
      " -0.         -0.          0.04575055 -0.         -0.          0.04482856\n",
      "  0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.         -0.         -0.          0.          0.0981359   0.\n",
      " -0.00674235 -0.          0.          0.         -0.         -0.          0.\n",
      " -0.          0.          0.00449802  0.05024302 -0.         -0.04133755\n",
      " -0.0196814   0.          0.          0.034645    0.         -0.          0.\n",
      " -0.01199628  0.          0.          0.          0.01925371  0.         -0.\n",
      "  0.02530867 -0.00878215  0.        ]\n",
      "lambda 0.0173945770182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "en = ElasticNetCV(l1_ratio=[0.1,0.5, 0.7, 0.9, 0.95, 0.99,0.1])\n",
    "en.fit(train_df[predictors], train_df[target])\n",
    "print 'train R2', en.score(train_df[predictors], train_df[target])\n",
    "print 'test R2', en.score(test_df[predictors], test_df[target])\n",
    "print 'wvec:', en.coef_\n",
    "print 'lambda', en.alpha_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "1. Make the following scatterplot\n",
    "    - Each point corresponds to one predictor in the data\n",
    "    - The x-value is the coefficient of that predictor under OLS regression\n",
    "    - The y-value is the coefficient of that predictor using ridge regularization\n",
    "2. Do the same for OLS vs Lasso, and OLS vs ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11980f890>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS8UBw8zMUnHAMDOzVBwwzMwslf8Ph0OH3L/Sph0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11980f790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = linreg.coef_\n",
    "y = rr.coef_\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1194c3650>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a8c2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = linreg.coef_\n",
    "y = lar.coef_\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x119824590>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181f1690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = linreg.coef_\n",
    "y = en.coef_\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: \n",
    "\n",
    "What is the story with the two 'large coefficients' found by OLS that are squashed by regularization? (You may have to do some digging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question:\n",
    "\n",
    "Can we tell from this process which predictors are _the most important_ for predicting violent crimes?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
