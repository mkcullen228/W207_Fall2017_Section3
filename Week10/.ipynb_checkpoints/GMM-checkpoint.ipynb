{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models: the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GMM.html\n",
    "\n",
    "In this notebook, I have a few tasks for you to try out related to GMMs. Not much guidance is given here, but the things to do are pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/mauracullen/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean(s) estimated with this 2 component GMM: \n",
      "[[-0.16988968  0.05150119]\n",
      " [ 2.45232862  4.96534618]]\n",
      "\n",
      "\n",
      "The covariances [SEE THE DOCS] estimated with this 2 component GMM: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GMM' object has no attribute 'covariances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c0b537170582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The mean(s) estimated with this\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"component GMM: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgm_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\\nThe covariances [SEE THE DOCS] estimated with this\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"component GMM: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgm_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcm_bright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'#FF0000'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#0000FF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GMM' object has no attribute 'covariances_'"
     ]
    }
   ],
   "source": [
    "# data generation\n",
    "np.random.seed(1)\n",
    "\n",
    "covar = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "\n",
    "dat_threedee = np.vstack((np.random.multivariate_normal([1, 1, 1], covar, 250), \n",
    "                          np.random.multivariate_normal([1, 5, 1], covar, 250),\n",
    "                          np.random.multivariate_normal([3, 2, 1], covar, 250)))\n",
    "\n",
    "dat_twodee = np.vstack((np.random.multivariate_normal([0, 0], [[10, 0], [0, 1]], 100),\n",
    "                        np.random.multivariate_normal([0, 5], [[1, 0.5], [0.5, 1]], 100),\n",
    "                        np.random.multivariate_normal([5, 5], [[5, 3], [3, 2]], 100)))\n",
    "\n",
    "dat_twodee_simple = np.vstack((np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], 100),\n",
    "                               np.random.multivariate_normal([0, 5], [[1, 0], [0, 1]], 100),\n",
    "                               np.random.multivariate_normal([5, 5], [[2, 0], [0, 2]], 100)))\n",
    "\n",
    "dat_twodee_headache = np.vstack((np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], 100),\n",
    "                                 np.random.multivariate_normal([0, 1], [[1, 0], [0, 1]], 100),\n",
    "                                 np.random.multivariate_normal([1, 1], [[2, 0], [0, 2]], 100)))\n",
    "\n",
    "comps = 2\n",
    "gm_mod = GaussianMixture(n_components = comps)\n",
    "\n",
    "gm_mod.fit(dat_twodee)\n",
    "y_hat = gm_mod.predict(dat_twodee)\n",
    "\n",
    "print \"The mean(s) estimated with this\", comps, \"component GMM: \\n\", gm_mod.means_\n",
    "\n",
    "print \"\\n\\nThe covariances [SEE THE DOCS] estimated with this\", comps, \"component GMM: \\n\", gm_mod.covariances_ \n",
    "\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "p = plt.subplot(1, 1, 1)\n",
    "p.scatter(dat_twodee[:, 0], dat_twodee[:, 1], c=y_hat, cmap=cm_bright)\n",
    "plt.title(\"Mysterious Rabbit Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common questions:\n",
    "1. The two means of the estimated gaussian distributions are printed out, add them as points to the plot. Do their locations make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Covariance Structures, components, AIC / BIC\n",
    "\n",
    "The goal of this question is to try out the flexibility of the class of GMM models, and to try out methods for choosing a model.\n",
    "\n",
    "Use the data:\n",
    "\n",
    "dat_twodee\n",
    "\n",
    "1. Try out the different covariance structures, see the argument `covariance_type`  Plot the results.\n",
    "\n",
    "2. Try out different numbers of components, see the argument `n_components` Plot the results.\n",
    "\n",
    "3. Use BIC to find the best choice for the settings in (1) and (2), see the `BIC` function, an example appears below. What model did you find works best? What model would you expect to work best, given how we generated the data?\n",
    "\n",
    "4. Do the parameters of the GMM match the parameters you used to generate the data?\n",
    "\n",
    "5. Try all of the above with dat_twodee_headache; what results do you see here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of BIC, a lower score relative to another model is better:\n",
      "BIC = 2834.51287621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x113209d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1131507d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# demo of the BIC function\n",
    "print \"Demo of BIC, a lower score relative to another model is better:\"\n",
    "print \"BIC =\", gm_mod.bic(dat_twodee)\n",
    "\n",
    "# demo for colors for up to 6 components so you can plot multiple component models\n",
    "cm_bright = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00FF', '#00FFFF', '#FFFF00'])\n",
    "\n",
    "p = plt.subplot(1, 1, 1)\n",
    "p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM vs Kmeans vs Agglomerative Clustering\n",
    "\n",
    "The goal of this question is to directly compare GMMs to other clustering techniques, and get an intuitive sense of the differences.\n",
    "\n",
    "Links to docs for kmeans and agglomerative clustering:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering\n",
    "\n",
    "Use the data:\n",
    "\n",
    "dat_twodee\n",
    "\n",
    "1. Compare the results you see with GaussianMixture, KMeans, and AgglomerativeClustering -- use all the three linkage types. Some demos are provided below. Try different numbers of clusters for all these algorithms. What differences do you see between the methods? Which one would you recommend using? Don't worry about trying to numerically score the models here, just use plots and your visual judgement.\n",
    "\n",
    "2. Try this again with the data: dat_twodee_simple and dat_twodee_headache; do you see any differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solution code goes here!\n",
    "\n",
    "cm_bright = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00FF', '#00FFFF', '#FFFF00'])\n",
    "\n",
    "def Proc():\n",
    "    # define this function to take in the number of clusters\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    p = plt.subplot(1, 5, 1)\n",
    "    p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n",
    "    plt.title('KMeans')\n",
    "    \n",
    "    p = plt.subplot(1, 5, 2)\n",
    "    p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n",
    "    plt.title('GaussianMixture') \n",
    "    \n",
    "    p = plt.subplot(1, 5, 3)\n",
    "    p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n",
    "    plt.title('Agglomerative') \n",
    "    \n",
    "    p = plt.subplot(1, 5, 4)\n",
    "    p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n",
    "    plt.title('Agglomerative') \n",
    "    \n",
    "    p = plt.subplot(1, 5, 5)\n",
    "    p.scatter(range(6), range(6), c=range(6), cmap=cm_bright)\n",
    "    plt.title('Agglomerative') \n",
    "\n",
    "Proc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and fitting data for GMMs\n",
    "\n",
    "The goal of this question is to see how GMMs do at recovering parameters. That is, if the data really came from a certain GMM, when and how well can we figure that out?\n",
    "\n",
    "Build off of the data generation code given below (particularly for 1) and the data generation code in the common section at the top.\n",
    "\n",
    "1. Make a function that generates spherical data for an arbitrary number of components and dimensions. This should have three arguments: a number of draws per component, a single scalar variance for all components and a matrix of means for the components. Try fitting a GMM with the appropriate number of components: can you recover the means? Try increasing the variance / separation of the cluster centers, can you recover the means?\n",
    "\n",
    "2. Generate data that is more appropriate for other `covariance_type` settings: focus on diag and full. **Do this in only two dimensions, more dimensions will be a bit of a pain to visualize**. Plot the generated data, run GMMs and see how well you can recover the _mean_ and _variance_ of each component. You only need to use 2 or 3 components here.\n",
    "\n",
    "NOTE: in all of the above, you may fit GMMs pretending you know the number of components (not really like real life...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some example code for generating data...\n",
    "draws_per_comp = 5\n",
    "variance = 1\n",
    "means = np.array([[0, 0], [10, 10], [10, -10]])\n",
    "\n",
    "GMM()\n",
    "\n",
    "print means.shape\n",
    "\n",
    "covar = np.diag([variance for i in range(means.shape[1])])\n",
    "\n",
    "gen_dat = np.vstack([np.random.multivariate_normal(means[i, :], covar, draws_per_comp) for i in range(means.shape[0])])\n",
    "\n",
    "gm_mod = GaussianMixture(n_components=3)\n",
    "\n",
    "gm_mod.fit(gen_dat)\n",
    "\n",
    "cm_bright = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    \n",
    "p = plt.subplot(1, 3, 1)\n",
    "p.scatter(gen_dat[:, 0], gen_dat[:, 1], c=gm_mod.predict(gen_dat), cmap=cm_bright)\n",
    "plt.title('GMM generated data') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
